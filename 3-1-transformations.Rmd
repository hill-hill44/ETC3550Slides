---
title: "3. Time series decomposition"
author: "3.1 Transformations and adjustments"
date: "OTexts.org/fpp3/"
classoption: aspectratio=169
titlepage: fpp3title.png
titlecolor: fpp3red
toc: false
output:
  binb::monash:
    colortheme: monashwhite
    fig_width: 7.5
    fig_height: 3
    keep_tex: no
    includes:
      in_header: fpp3header.tex
---

```{r setup, include=FALSE}
source("setup.R")
library(purrr)
library(transformr) # Just to get it on renv
library(gganimate)
```

## Per capita adjustments

```{r gdp-per-capita}
global_economy |>
  filter(Country == "Australia") |>
  autoplot(GDP)
```

## Per capita adjustments

```{r gdp-per-capita2}
global_economy |>
  filter(Country == "Australia") |>
  autoplot(GDP / Population)
```

<!--
## Your turn

Consider the GDP information in `global_economy`. Plot the GDP per capita for each country over time. Which country has the highest GDP per capita? How has this changed over time? -->

## Inflation adjustments

```{r retail_cpi, message=FALSE, warning=FALSE, fig.show='hide'}
print_retail <- aus_retail |>
  filter(Industry == "Newspaper and book retailing") |>
  group_by(Industry) |>
  index_by(Year = year(Month)) |>
  summarise(Turnover = sum(Turnover))
aus_economy <- global_economy |>
  filter(Code == "AUS")
print_retail |>
  left_join(aus_economy, by = "Year") |>
  mutate(Adjusted_turnover = Turnover / CPI * 100) |>
  pivot_longer(c(Turnover, Adjusted_turnover), values_to = "Turnover") |>
  mutate(name = factor(name, levels = c("Turnover", "Adjusted_turnover"))) |>
  ggplot(aes(x = Year, y = Turnover)) +
  geom_line() +
  facet_grid(name ~ ., scales = "free_y") +
  labs(title = "Turnover: Australian print media industry", y = "$AU")
```

## Inflation adjustments

```{r ref.label = 'retail_cpi', message=FALSE, warning=FALSE, echo=FALSE, fig.height=4, fig.width=8}
```

## Mathematical transformations
\fontsize{13}{15}\sf

If the data show different variation at different levels of the series, then a transformation can be useful.
\pause

Denote original observations as $y_1,\dots,y_T$ and transformed
observations as $w_1, \dots, w_T$.
\pause

\begin{block}{\footnotesize Mathematical transformations for stabilizing
variation}
\begin{tabular}{llc}
Square root & $w_t = \sqrt{y_t}$ & $\downarrow$ \\[0.2cm]
Cube root & $w_t = \sqrt[3]{y_t}$ & Increasing \\[0.2cm]
Logarithm & $w_t = \log(y_t)$  & strength
\end{tabular}
\end{block}
\pause

Logarithms, in particular, are useful because they are more interpretable: changes in a log value are **relative (percent) changes on the original scale**.

## Mathematical transformations

```{r food}
food <- aus_retail |>
  filter(Industry == "Food retailing") |>
  summarise(Turnover = sum(Turnover))
```

```{r food-plot, echo = FALSE}
food |> autoplot(Turnover) +
  labs(y = "Turnover ($AUD)")
```

## Mathematical transformations

```{r food-sqrt1}
food |> autoplot(sqrt(Turnover)) +
  labs(y = "Square root turnover")
```

## Mathematical transformations

```{r food-cbrt}
food |> autoplot(Turnover^(1 / 3)) +
  labs(y = "Cube root turnover")
```

## Mathematical transformations

```{r food-log}
food |> autoplot(log(Turnover)) +
  labs(y = "Log turnover")
```

## Mathematical transformations

```{r food-inverse}
food |> autoplot(-1 / Turnover) +
  labs(y = "Inverse turnover")
```

## Box-Cox transformations

Each of these transformations is close to a member of the
family of \textbf{Box-Cox transformations}:
$$w_t = \left\{\begin{array}{ll}
        \log(y_t),      & \quad \lambda = 0; \\
        (sign(y_t)|y_t|^\lambda-1)/\lambda ,         & \quad \lambda \ne 0.
\end{array}\right.
$$\pause

* Actually the Bickel-Doksum transformation (allowing for $y_t<0$)
* $\lambda=1$: (No substantive transformation)
* $\lambda=\frac12$: (Square root plus linear transformation)
* $\lambda=0$: (Natural logarithm)
* $\lambda=-1$: (Inverse plus 1)

## Box-Cox transformations

```{r food-anim, cache=TRUE, echo=FALSE, fig.show='animate', interval=1/10, message=FALSE, fig.height=4.5, fig.width=9, aniopts='controls,buttonsize=0.3cm,width=13.5cm'}
food |>
  mutate(!!!set_names(map(seq(0, 1, 0.01), ~ expr(fabletools::box_cox(Turnover, !!.x))), seq(0, 1, 0.01))) |>
  select(-Turnover) |>
  pivot_longer(-Month, names_to = "lambda", values_to = "Turnover") |>
  mutate(lambda = as.numeric(lambda)) |>
  ggplot(aes(x = Month, y = Turnover)) +
  geom_line() +
  transition_states(1 - lambda, state_length = 0) +
  view_follow() +
  labs(title = "Box-Cox transformed food retailing turnover (lambda = {format(1 - as.numeric(closest_state), digits = 2)})")
```

## Box-Cox transformations

```{r food-lambda}
food |>
  features(Turnover, features = guerrero)
```

\pause\fontsize{13}{15}\sf

* This attempts to balance the seasonal fluctuations and random variation across the series.
* Always check the results.
* A low value of $\lambda$ can give extremely large prediction intervals.

## Box-Cox transformations

```{r food-bc}
food |> autoplot(box_cox(Turnover, 0.0524)) +
  labs(y = "Box-Cox transformed turnover")
```

## Transformations
\fontsize{13}{15}\sf

* Often no transformation needed.
* Simple transformations are easier to explain and work well enough.
* Transformations can have very large effect on PI.
* If some data are zero or negative, then use $\lambda>0$.
* `log1p()` can also be useful for data with zeros.
* Choosing logs is a simple way to force forecasts to be positive
* Transformations must be reversed to obtain forecasts on the original scale. (Handled automatically by `fable`.)
